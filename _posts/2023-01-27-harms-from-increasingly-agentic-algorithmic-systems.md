---
title: "Harms from Increasingly Agentic Algorithmic Systems"
categories:
  - AI Technical Papers
---



## Summary of "Harms from Increasingly Agentic Algorithmic Systems"

**Authors:** Abhinit Kumar Ambastha, Leong Tze Yun  
**Link to the paper:** [arXiv:2301.12055](https://arxiv.org/abs/2301.12055)  
**Date Published:** January 27, 2023

**This summary was generated by GPT-4o. There may be errors or omissions.**

The paper "Harms from Increasingly Agentic Algorithmic Systems" by Abhinit Kumar Ambastha and Leong Tze Yun explores the potential risks and harms that could arise as artificial intelligence (AI) systems become more advanced and capable of making autonomous decisions. These systems, described as "agentic," are designed to operate with a high degree of independence, performing tasks and making decisions without human intervention. While this autonomy can bring significant benefits in terms of efficiency and capability, it also introduces substantial risks.

One major concern is the potential for these agentic systems to cause harm due to errors or unintended behaviors. As AI systems become more complex, it becomes increasingly difficult to predict how they will behave in various situations. This unpredictability can lead to scenarios where the AI makes decisions that have harmful consequences. For example, an AI system tasked with managing a power grid might shut down essential services if it misinterprets data or fails to consider all relevant factors.

Another critical issue is the ethical implications of allowing AI systems to make decisions that significantly impact human lives. These decisions can range from determining eligibility for loans to making medical diagnoses. When AI systems make such high-stakes decisions, there is a risk of bias and unfair treatment, particularly if the underlying data or algorithms are flawed. This can exacerbate existing social inequalities and lead to widespread harm.

The authors also highlight the challenge of accountability. When an autonomous AI system causes harm, it is often unclear who should be held responsible. This lack of accountability can lead to situations where individuals or organizations affected by the AI's decisions have little recourse for seeking justice or compensation. Establishing clear lines of responsibility is essential to ensure that those deploying and using these systems are held accountable for their actions.

The paper suggests that the rapid development and deployment of AI systems are driven by competitive pressures among companies and nations. This race to achieve technological superiority can lead to cutting corners in safety and ethical considerations. The authors argue for a more cautious approach, emphasizing the need for comprehensive testing and evaluation of AI systems before they are widely deployed.

To mitigate these risks, the authors propose several strategies. One recommendation is to implement stricter regulatory frameworks that govern the development and use of AI systems. These regulations should ensure that AI technologies are thoroughly tested for safety and fairness before they are allowed to operate autonomously. Additionally, the authors advocate for increased transparency in AI development processes. This includes making the data and algorithms used by AI systems accessible for scrutiny by independent experts.

Another proposed measure is the development of robust oversight mechanisms to monitor AI systems in real-time. These mechanisms would help detect and address harmful behaviors quickly, minimizing the potential for widespread damage. The authors also suggest that AI systems should be designed with fail-safes and human intervention capabilities, ensuring that humans can step in and override the AI's decisions if necessary.

In conclusion, while agentic AI systems offer significant potential benefits, they also pose substantial risks that must be carefully managed. By implementing stringent regulatory measures, ensuring transparency, and developing robust oversight mechanisms, society can better safeguard against the harms that these advanced AI systems might cause. The paper calls for a balanced approach that prioritizes safety and ethical considerations alongside technological advancement.

